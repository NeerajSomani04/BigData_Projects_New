Couple of Questions:

1) In section "Queries to run", its mention that Comment_ID must match across all 3 dataset but looks like Comment_ID is not present in "Post_meta.zip" file data set. Hence, comment_ID is present in 2 data sets "comment_text" and "comment_info_jsonl". Is this understanding correct? I need to consider it only for these 2 data sets.

2) 


Below are commands used to perform some activity -->

Below command to create Hive database --> 
CREATE DATABASE IF NOT EXISTS Viacom_Test; 

Drop table comment_text;
CREATE TABLE IF NOT EXISTS comment_text (
message STRING,
h_id STRING)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE;

Load data local inpath '/home/dkothari/vi-com/BigData_Projects_New/comment_text' into table comment_text;

describe formatted comment_text; --> this command can be used to see the details of hive table.

Below is the hive dataware house location for our database -->
hdfs://nn01.itversity.com:8020/apps/hive/warehouse/viacom_test.db/comment_text

hdfs dfs -put /home/dkothari/vi-com/BigData_Projects_New/post_meta/ vi-com/BigData_Project/post_meta

Below command is for post_meta parquet files --  COMPRESSED WITH SNAPPY

Drop table post_meta;

CREATE EXTERNAL TABLE IF NOT EXISTS post_meta (post_h_id STRING, post_created_time TIMESTAMP, name_h_id STRING, type STRING) 
STORED AS PARQUET 
TBLPROPERTIES ('PARQUET.COMPRESS'='SNAPPY');

Load data local inpath '/home/dkothari/vi-com/BigData_Projects_New/post_meta' into table post_meta;

describe formatted post_meta;

Drop table comment_info_jsonl;

CREATE EXTERNAL TABLE IF NOT EXISTS comment_info_jsonl (
text STRING)
ROW FORMAT SERDE 'org.apache.hive.hcatalog.data.JsonSerDe';

CREATE EXTERNAL TABLE IF NOT EXISTS comment_info_jsonl (
h_id STRING
, posts struct< 
data: array < struct <
comments: struct < 
data: array< struct < 
comment_count: INT
, comments: struct < 
data: array < struct < 
comment_count: INT
, created_time: STRING
, h_id: STRING
, parent: struct < 
h_id: STRING
>
, up_likes: INT
> > >
, created_time: STRING
, h_id: STRING
, up_likes: INT 
> > >
, h_id: STRING 
> > >
)
ROW FORMAT SERDE 'org.apache.hive.hcatalog.data.JsonSerDe'
STORED AS TEXTFILE;

I downloaded jar from below path --
http://snowplow-hosted-assets.s3.amazonaws.com/third-party/rcongiu/json-serde-1.1.6-jar-with-dependencies.jar

add jar /home/dkothari/json-serde-1.1.6-jar-with-dependencies.jar; -- this command added the jar in hive consol.

-- this serde is working -- 'org.apache.hive.hcatalog.data.JsonSerDe'
we might need this serde -- org.openx.data.jsonserde.JsonSerDe 

Load data local inpath '/home/dkothari/vi-com/BigData_Projects_New/comment_info_jsonl' into table comment_info_jsonl;

for cloudera -->
Load data local inpath '/home/cloudera/vi-com/BigData_Projects_New/comment_info_jsonl' into table comment_info_jsonl;


Below are queries:
1) this query is used to get count of posts :
select count(distinct post_h_id) from (select explode(posts.data.h_id) as post_h_id from comment_info_jsonl) as temp; -- 297 distinct
select count(distinct post_h_id) from post_meta; -- 3531 distinct

select count(distinct PM.post_h_id)
from (select explode(posts.data.h_id) as post_h_id from comment_info_jsonl) as CIJ 
INNER JOIN post_meta as PM
on CIJ.post_h_id = PM.post_h_id; -- 282 distinct 

Questions for Queries:

1) Which day had the highest number of top level comments (excluding replies)?
Solution:

select to_date(temp1.comment_created_time) as comment_created_time, sum(temp1.comment_count) as total_comments
from 
(select CIE.*,
row_number() over (partition by comment_id order by comment_created_time desc, comment_like_count desc, comment_count desc) as row_num
from comment_info_exploded CIE 
INNER JOIN post_meta PM
on PM.post_h_id = CIE.post_id
INNER JOIN comment_text CT
ON CT.h_id = CIE.comment_id) 
as temp1
where temp1.row_num = 1
group by to_date(temp1.comment_created_time)
order by total_comments desc
limit 1;

Result :- Date: 2018-01-10 (10-Jan-2018) , Total comments: 610

---------------------------
Below are few SQLs used to create above solution.

select 
sum(comment_count) as total_comment_count
group by created_time of top level comments
order by total_comment_count desc 
limit 1;

select 
post_data.h_id,
comments_data.comment_count,
comments_data.up_likes
from comment_info_jsonl 
LATERAL VIEW explode(posts.data) exploded_post as post_data
lateral view explode(post_data.comments.data) comments_exploded as comments_data
limit 1;

select 
post_data.h_id as post_id,
comments_data.comment_count,
comments_data.up_likes as comment_like_count,
comments_data.h_id as comment_id,
comments_data.created_time as comment_created_time,
reply_data.comment_count as reply_count,
reply_data.created_time as reply_created_time,
reply_data.h_id as reply_id,
reply_data.parent.h_id as reply_parent_comment_id,
reply_data.up_likes as reply_like_count
from comment_info_jsonl 
LATERAL VIEW explode(posts.data) exploded_post as post_data
lateral view explode(post_data.comments.data) comments_exploded as comments_data
lateral view explode(comments_data.comments.data) reply_exploded as reply_data
where post_data.h_id = 'MTE0MDQzMTc1MzUyMDI3XzE1OTM4MDUzOTQwNDI0NTc'
limit 5;

Drop table comment_info_exploded;
Create table comment_info_exploded as
select 
post_data.h_id as post_id,
comments_data.comment_count,
comments_data.up_likes as comment_like_count,
comments_data.h_id as comment_id,
cast(from_unixtime(unix_timestamp(regexp_replace(comments_data.created_time, 'T',' '))) as timestamp) as comment_created_time
from comment_info_jsonl 
LATERAL VIEW explode(posts.data) exploded_post as post_data
lateral view explode(post_data.comments.data) comments_exploded as comments_data;


select cast(to_date(from_unixtime(unix_timestamp(regexp_replace('2018-06-05T08:02:59Z', 'T',' ')))) as date);

yyyy-MM-dd'T'hh:mm:ssZ


select cast(to_date(from_unixtime(unix_timestamp(comments_data.created_time, 'yyyy-MM-ddThh:mm:ssZ'))) as date)


select * 
from comment_info_exploded CFE 
INNER JOIN post_meta PM
on PM.post_h_id = CFE.post_id
INNER JOIN comment_text CT
ON CT.h_id = CFE.comment_id
limit 5;




Links for comments and posts Hive data model 

Nice hive example article:
https://medium.com/datadriveninvestor/analyzing-twitter-feeds-using-hive-7e074025f295

https://blog.cloudera.com/blog/2012/11/analyzing-twitter-data-with-hadoop-part-3-querying-semi-structured-data-with-hive/

https://github.com/rcongiu/Hive-JSON-Serde

https://www.google.com/search?q=relational+data+model+to+store+facebook+post+comments&tbm=isch&source=hp&safe=active&sa=X&ved=2ahUKEwiW2v2M7IzgAhXLT98KHWmnDscQsAR6BAgAEAE

https://data.stackexchange.com/stackoverflow/query/new

https://dba.stackexchange.com/questions/174878/how-to-store-likes-and-comments-of-posts-in-database

https://www.slideshare.net/cloudera/nested-types-in-impala-55344174

https://www.cloudera.com/documentation/enterprise/5-5-x/topics/impala_complex_types.html
https://www.cloudera.com/documentation/enterprise/5-5-x/topics/impala_complex_types.html#complex_types_ex_hive_etl

Below are few links to work on ElasticSearch for the data load and analysis:
https://gist.github.com/vinodnerella/15dabed07ac4815e4792d63cf8e4ed51

https://medium.com/@ashish_fagna/getting-started-with-elasticsearch-creating-indices-inserting-values-and-retrieving-data-e3122e9b12c6

https://github.com/Moshe/elasticsearch_loader

Elastic Search deep dive on linux academy
https://dzone.com/articles/what-is-elasticsearch-and-how-it-can-be-useful

https://www.elastic.co/blog/found-elasticsearch-as-nosql
