Below command to create Hive database --> 

CREATE DATABASE IF NOT EXISTS Viacom_Test; 

Below command to create hive table for comment_text dataset.

-- Drop table comment_text; -- use this command to drop table if needed.

CREATE TABLE IF NOT EXISTS comment_text (
message STRING,
h_id STRING)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE;

----------- new table could be like below -----
CREATE TABLE IF NOT EXISTS comment_text (
message STRING,
h_id STRING)
CLUSTERED BY (h_id) SORTED BY (message) into 64 buckets
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE;
----------- 
Use below command to load data from local system to hive table.

Load data local inpath '/home/dkothari/vi-com/BigData_Projects_New/comment_text' into table comment_text;

select count(*) from comment_text; -- 859217
select count(*) from (select distinct * from comment_text) as temp; -- 859183

Below command is to create table for post_meta dataset files.

CREATE EXTERNAL TABLE IF NOT EXISTS post_meta (post_h_id STRING, post_created_time TIMESTAMP, name_h_id STRING, type STRING) 
STORED AS PARQUET 
TBLPROPERTIES ('PARQUET.COMPRESS'='SNAPPY');

--------- new table could be ----
CREATE EXTERNAL TABLE IF NOT EXISTS post_meta (post_h_id STRING, post_created_time TIMESTAMP, name_h_id STRING, type STRING)
PARTITIONED BY(type STRING)
CLUSTERED BY(post_h_id) INTO 8 BUCKETS
STORED AS PARQUET 
TBLPROPERTIES ('PARQUET.COMPRESS'='SNAPPY');
-----------------------
below command is to load data from local system to post_meta tables.

Load data local inpath '/home/dkothari/vi-com/BigData_Projects_New/post_meta' into table post_meta;

select count(*) from post_meta; -- 40800
select count(*) from (select distinct * from post_meta) as temp; -- 3531

Below command is to create table for comment_info_jsonl dataset.

CREATE EXTERNAL TABLE IF NOT EXISTS comment_info_jsonl (
h_id STRING
, posts struct< 
data: array < struct <
comments: struct < 
data: array< struct < 
comment_count: INT
, comments: struct < 
data: array < struct < 
comment_count: INT
, created_time: STRING
, h_id: STRING
, parent: struct < 
h_id: STRING
>
, up_likes: INT
> > >
, created_time: STRING
, h_id: STRING
, up_likes: INT 
> > >
, h_id: STRING 
> > >
)
ROW FORMAT SERDE 'org.apache.hive.hcatalog.data.JsonSerDe'
STORED AS TEXTFILE;


Load data local inpath '/home/cloudera/vi-com/BigData_Projects_New/comment_info_jsonl' into table comment_info_jsonl;

select count(*) from comment_info_jsonl; -- 744

run below command to add json serde to parse json files properly.

add jar /usr/lib/hive-hcatalog/share/hcatalog/hive-hcatalog-core.jar ;

select count(*) from comment_info_exploded_with_replies_new; -- 5704
select count(*) from (select distinct * from comment_info_exploded_with_replies_new) as temp; -- 5704

SET mapreduce.job.reduces=number Of Reducers
1. SET hive.exec.dynamic.partition= true; 
2. SET hive.exec.dynamic.partition.mode= nonstrict;
3. partition column should be last column in selet query


----------- finalized ------
Drop table comment_info_exploded_with_replies_new_with_keys;

Create EXTERNAL TABLE IF NOT EXISTS comment_info_exploded_with_replies_new_with_keys 
(post_id STRING, Comment_count int, comment_like_count int, comment_id STRING, comment_created_time timestamp,
reply_count int, reply_created_time timestamp, reply_id STRING, reply_parent_comment_id STRING, reply_like_count int)
PARTITIONED BY(comment_created_date date)
CLUSTERED BY(post_id, comment_id) INTO 16 BUCKETS
STORED AS TEXTFILE;


Insert overwrite table comment_info_exploded_with_replies_new_with_keys PARTITION (comment_created_date)
select distinct * from (select 
post_data.h_id as post_id,
comments_data.comment_count,
comments_data.up_likes as comment_like_count,
comments_data.h_id as comment_id,
cast(from_unixtime(unix_timestamp(regexp_replace(comments_data.created_time, 'T',' '))) as timestamp) as comment_created_time,
reply_data.comment_count as reply_count,
cast(from_unixtime(unix_timestamp(regexp_replace(reply_data.created_time, 'T',' '))) as timestamp) as reply_created_time,
reply_data.h_id as reply_id,
reply_data.parent.h_id as reply_parent_comment_id,
reply_data.up_likes as reply_like_count,
cast(cast(from_unixtime(unix_timestamp(regexp_replace(comments_data.created_time, 'T',' '))) as timestamp) as date) as comment_created_date
from comment_info_jsonl 
LATERAL VIEW explode(posts.data) exploded_post as post_data
lateral view explode(post_data.comments.data) comments_exploded as comments_data
lateral view explode(comments_data.comments.data) reply_exploded as reply_data) as temp;

----------------



